#!/bin/bash
# etcd Comprehensive Health Check Script
# Purpose: Monitors etcd cluster health and performs auto-recovery
#
# Problem this solves:
# - etcd can become unhealthy due to network partitions
# - Cluster leadership changes need monitoring
# - Database size can grow without bounds
# - Network timeouts can cause service degradation
#
# How it works:
# 1. Checks local etcd endpoint health
# 2. Verifies cluster has exactly one leader
# 3. Monitors database size and warns if excessive
# 4. Attempts basic recovery for common issues
#
# Exit codes:
# - 0: Healthy
# - 1: Critical failure requiring intervention

set -euo pipefail

# Configuration
ETCD_ENDPOINTS="http://localhost:2379"
LOG_TAG="etcd-health"
MAX_DB_SIZE_MB=1024  # Warn if database > 1GB
TIMEOUT_SECONDS=10

# Logging function
log() {
    local level=$1
    shift
    logger -t "${LOG_TAG}" -p "daemon.${level}" "$@"
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [$level] $@"
}

# Set etcd API version
export ETCDCTL_API=3
export ETCDCTL_ENDPOINTS="${ETCD_ENDPOINTS}"

# Check if etcd service is running
check_service_running() {
    if ! systemctl is-active --quiet etcd; then
        log "error" "etcd service is not running"
        return 1
    fi
    return 0
}

# Check local endpoint health
check_local_endpoint() {
    log "info" "Checking local etcd endpoint health"
    
    if ! timeout ${TIMEOUT_SECONDS} etcdctl endpoint health 2>/dev/null; then
        log "error" "Local etcd endpoint is unhealthy"
        return 1
    fi
    
    log "info" "Local etcd endpoint is healthy"
    return 0
}

# Check cluster status and leadership
check_cluster_health() {
    log "info" "Checking etcd cluster health"
    
    # Get cluster status
    local status_output
    if ! status_output=$(timeout ${TIMEOUT_SECONDS} etcdctl endpoint status --write-out=json 2>/dev/null); then
        log "error" "Cannot get cluster status"
        return 1
    fi
    
    # Count leaders
    local leader_count
    leader_count=$(echo "$status_output" | jq -r '[.[] | select(.Status.leader == true)] | length' 2>/dev/null || echo "0")
    
    if [ "$leader_count" -ne 1 ]; then
        log "error" "Expected 1 leader, found $leader_count"
        return 1
    fi
    
    # Check if this node is the leader
    local is_leader
    is_leader=$(echo "$status_output" | jq -r --arg endpoint "$ETCD_ENDPOINTS" '
        .[] | select(.Endpoint == $endpoint) | .Status.leader' 2>/dev/null || echo "false")
    
    if [ "$is_leader" = "true" ]; then
        log "info" "This node is the etcd leader"
    else
        log "info" "This node is an etcd follower"
    fi
    
    return 0
}

# Check database size
check_database_size() {
    log "info" "Checking etcd database size"
    
    local db_size_bytes
    if ! db_size_bytes=$(timeout ${TIMEOUT_SECONDS} etcdctl endpoint status --write-out=json 2>/dev/null | \
        jq -r --arg endpoint "$ETCD_ENDPOINTS" '.[] | select(.Endpoint == $endpoint) | .Status.dbSize' 2>/dev/null); then
        log "warning" "Cannot determine database size"
        return 0
    fi
    
    local db_size_mb=$((db_size_bytes / 1024 / 1024))
    
    if [ "$db_size_mb" -gt "$MAX_DB_SIZE_MB" ]; then
        log "warning" "etcd database size is large: ${db_size_mb}MB (threshold: ${MAX_DB_SIZE_MB}MB)"
        log "info" "Consider running: etcdctl defrag --cluster"
    else
        log "info" "etcd database size is acceptable: ${db_size_mb}MB"
    fi
    
    return 0
}

# Check cluster member connectivity
check_member_connectivity() {
    log "info" "Checking etcd cluster member connectivity"
    
    # Get all cluster endpoints
    local all_endpoints
    if ! all_endpoints=$(timeout ${TIMEOUT_SECONDS} etcdctl member list --write-out=json 2>/dev/null | \
        jq -r '.members[] | .clientURLs[]' 2>/dev/null | tr '\n' ',' | sed 's/,$//'); then
        log "warning" "Cannot get cluster member list"
        return 0
    fi
    
    # Test connectivity to all endpoints
    export ETCDCTL_ENDPOINTS="$all_endpoints"
    
    if timeout ${TIMEOUT_SECONDS} etcdctl endpoint health --endpoints="$all_endpoints" >/dev/null 2>&1; then
        log "info" "All cluster members are healthy"
    else
        log "warning" "Some cluster members may be unhealthy"
        # Show detailed status
        timeout ${TIMEOUT_SECONDS} etcdctl endpoint health --endpoints="$all_endpoints" 2>/dev/null || true
    fi
    
    # Reset to local endpoint
    export ETCDCTL_ENDPOINTS="${ETCD_ENDPOINTS}"
    return 0
}

# Attempt basic recovery
attempt_recovery() {
    log "info" "Attempting basic etcd recovery"
    
    # Check if we can perform basic operations
    local test_key="/_health_check_$(date +%s)"
    local test_value="health_check"
    
    if timeout ${TIMEOUT_SECONDS} etcdctl put "$test_key" "$test_value" >/dev/null 2>&1; then
        log "info" "etcd write operation successful"
        
        # Clean up test key
        timeout ${TIMEOUT_SECONDS} etcdctl del "$test_key" >/dev/null 2>&1 || true
        return 0
    else
        log "error" "etcd write operation failed"
        return 1
    fi
}

# Main health check function
perform_health_check() {
    log "info" "Starting etcd health check on {{ inventory_hostname }}"
    
    local exit_code=0
    
    # Check service status
    if ! check_service_running; then
        exit_code=1
    fi
    
    # Check local endpoint
    if ! check_local_endpoint; then
        exit_code=1
    fi
    
    # If local endpoint is healthy, check cluster
    if [ $exit_code -eq 0 ]; then
        if ! check_cluster_health; then
            exit_code=1
        fi
        
        # Check database size (non-critical)
        check_database_size || true
        
        # Check member connectivity (non-critical)
        check_member_connectivity || true
        
        # Test basic operations
        if ! attempt_recovery; then
            exit_code=1
        fi
    fi
    
    if [ $exit_code -eq 0 ]; then
        log "info" "etcd health check completed successfully"
    else
        log "error" "etcd health check failed"
    fi
    
    return $exit_code
}

# Script entry point
main() {
    local mode="${1:-check}"
    
    case "${mode}" in
        check)
            perform_health_check
            ;;
        status)
            # Quick status check
            if check_service_running && check_local_endpoint; then
                echo "etcd is healthy"
                exit 0
            else
                echo "etcd is unhealthy"
                exit 1
            fi
            ;;
        *)
            echo "Usage: $0 [check|status]"
            exit 1
            ;;
    esac
}

# Execute main function
main "$@"