---
- name: Install PostgreSQL with Patroni HA
  hosts: postgres_nodes
  become: true
  vars:
    postgresql_version: "17"
    patroni_version: "4.0.6"
    postgres_version: "17"
    postgres_port: 5432
    patroni_rest_api_port: 8008
    consul_client_port: 8500
    etcd_client_port: 2379
    postgres_password: "{{ vault_postgres_password }}"
    postgres_replication_password: "{{ vault_postgres_replication_password }}"
    postgres_user: "postgres"
    postgres_db_name: "proposalsapp"
    # Resource settings - adjust based on server RAM
    postgres_shared_buffers: "2GB"
    postgres_effective_cache_size: "6GB"
    postgres_work_mem: "16MB"

  tasks:
    - name: Set connection to use tailscale IP if available
      set_fact:
        ansible_host: "{{ tailscale_ip }}"
      when: tailscale_ip is defined and tailscale_ip != ''
    
    # Pre-flight check: Ensure etcd is running on all nodes
    - name: Verify etcd cluster health
      shell: |
        export ETCDCTL_API=3
        # Check if etcd is healthy on all nodes
        endpoints="{% for host in groups['postgres_nodes'] %}{{ hostvars[host]['tailscale_ip'] }}:{{ etcd_client_port }}{% if not loop.last %},{% endif %}{% endfor %}"
        
        if ! /usr/local/bin/etcdctl endpoint health --endpoints="$endpoints"; then
          echo "ERROR: etcd cluster is not healthy"
          exit 1
        fi
        
        echo "OK: etcd cluster verified healthy across all nodes"
      register: etcd_health
      changed_when: false
      run_once: true
    - name: Add PostgreSQL APT key
      apt_key:
        url: https://www.postgresql.org/media/keys/ACCC4CF8.asc
        state: present

    - name: Add PostgreSQL repository
      apt_repository:
        repo: "deb http://apt.postgresql.org/pub/repos/apt {{ ansible_distribution_release }}-pgdg main"
        state: present

    - name: Install PostgreSQL and dependencies
      apt:
        name:
          - "postgresql-{{ postgresql_version }}"
          - "postgresql-contrib-{{ postgresql_version }}"
          - "postgresql-{{ postgresql_version }}-repack"
          - python3-pip
          - python3-psycopg2
          - libpq-dev
        state: present

    - name: Check if Patroni service exists
      systemd:
        name: patroni
      register: patroni_service_check
      failed_when: false

    - name: Stop Patroni service if running
      systemd:
        name: patroni
        state: stopped
      when: patroni_service_check.status.ActiveState is defined and patroni_service_check.status.ActiveState == "active"

    - name: Check PostgreSQL service status
      systemd:
        name: postgresql
      register: postgresql_service
      failed_when: false

    - name: Stop PostgreSQL service
      systemd:
        name: postgresql
        state: stopped
        enabled: no
      when: postgresql_service.status.ActiveState is defined and postgresql_service.status.ActiveState == "active"

    - name: Install pipx and venv support
      apt:
        name:
          - pipx
          - python3-venv
          - python3-full
        state: present

    - name: Check if Patroni is already installed
      stat:
        path: /var/lib/postgresql/.local/bin/patroni
      register: patroni_installed

    - name: Install Patroni and dependencies for postgres user
      shell: |
        su - postgres -c '
        export PATH="/usr/bin:$PATH"
        pipx install "patroni[etcd3]=={{ patroni_version }}" --include-deps
        pipx inject patroni psycopg2-binary etcd3 cdiff
        # Remove consul support to ensure etcd is used as DCS
        pipx runpip patroni uninstall -y py-consul || true
        '
      when: not patroni_installed.stat.exists

    - name: Ensure Patroni has all dependencies
      shell: |
        su - postgres -c '
        export PATH="/usr/bin:$PATH"
        pipx inject patroni etcd3 cdiff --force
        # Remove consul support to ensure etcd is used as DCS
        pipx runpip patroni uninstall -y py-consul || true
        '
      when: patroni_installed.stat.exists

    - name: Create Patroni configuration directory
      file:
        path: /etc/patroni
        state: directory
        mode: "0755"

    - name: Ensure PostgreSQL data directory is clean for fresh install
      file:
        path: /var/lib/postgresql/{{ postgresql_version }}/data
        state: absent

    - name: Create PostgreSQL data directory
      file:
        path: /var/lib/postgresql/{{ postgresql_version }}/data
        state: directory
        owner: postgres
        group: postgres
        mode: "0700"



    - name: Generate Patroni configuration
      template:
        src: ../templates/patroni-etcd-only.yml.j2
        dest: /etc/patroni/patroni.yml
        owner: postgres
        group: postgres
        mode: "0640"
    
    - name: Generate Patroni bootstrap SQL script
      template:
        src: ../templates/patroni-bootstrap.sql.j2
        dest: /tmp/patroni-bootstrap.sql
        owner: postgres
        group: postgres
        mode: "0644"
    
    - name: Generate Patroni post-init wrapper script
      template:
        src: ../templates/patroni-post-init.sh.j2
        dest: /tmp/patroni-post-init.sh
        owner: postgres
        group: postgres
        mode: "0755"

    - name: Create Patroni systemd service
      copy:
        content: |
          [Unit]
          Description=Patroni PostgreSQL HA
          After=syslog.target network.target etcd.service
          Wants=etcd.service

          [Service]
          Type=simple
          User=postgres
          Group=postgres
          Environment="PATH=/var/lib/postgresql/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
          ExecStart=/var/lib/postgresql/.local/bin/patroni /etc/patroni/patroni.yml
          ExecReload=/bin/kill -s HUP $MAINPID
          KillMode=process
          TimeoutSec=30
          Restart=always
          RestartSec=10

          [Install]
          WantedBy=multi-user.target
        dest: /etc/systemd/system/patroni.service
      notify:
        - reload systemd
        - restart patroni

    # Clean any existing Patroni state to ensure fresh start
    - name: Clean existing Patroni state from etcd
      shell: |
        export ETCDCTL_API=3
        # Delete all keys under the Patroni namespace
        /usr/local/bin/etcdctl del /service/proposalsapp --prefix || true
        # Also clean up any Consul keys if they exist
        curl -X DELETE http://localhost:8500/v1/kv/service/proposalsapp?recurse || true
      run_once: true

    # Start nodes in order to ensure proper cluster formation
    - name: Start Patroni on designated primary node first
      systemd:
        name: patroni
        state: started
        enabled: yes
      when: postgres_role == 'primary'

    - name: Wait for primary to initialize cluster
      pause:
        seconds: 45
        prompt: "Waiting for primary to initialize and register in etcd"
      when: postgres_role == 'primary'
    
    - name: Create wait script for Patroni initialization
      template:
        src: ../templates/wait-for-patroni.sh.j2
        dest: /tmp/wait-for-patroni.sh
        mode: "0755"
      when: postgres_role == 'primary'
    
    - name: Wait for Patroni to fully initialize the database
      shell: /tmp/wait-for-patroni.sh
      when: postgres_role == 'primary'
      register: postgres_ready_check

    - name: Wait for cluster state to stabilize in etcd
      pause:
        seconds: 30
        prompt: "Waiting for etcd to achieve consensus on cluster state"
      run_once: true
    
    - name: Ensure required PostgreSQL roles exist  
      environment:
        PGPASSWORD: "{{ postgres_password }}"
      shell: |
        # Check if proposalsapp role exists, create if not
        if ! psql -h localhost -U postgres -d postgres -tAc "SELECT 1 FROM pg_roles WHERE rolname='proposalsapp';" | grep -q 1; then
          echo "Creating proposalsapp role..."
          psql -h localhost -U postgres -d postgres -f /tmp/patroni-bootstrap.sql
        else
          echo "Role proposalsapp already exists"
        fi
        
        # Verify roles were created
        echo "Current roles:"
        psql -h localhost -U postgres -d postgres -c "SELECT rolname FROM pg_roles WHERE rolname IN ('proposalsapp', 'replicator');"
      when: postgres_role == 'primary'
      run_once: true
      register: role_creation

    - name: Verify initialize key is in etcd
      shell: |
        #!/bin/bash
        set -e
        
        export ETCDCTL_API=3
        
        echo "Checking for initialize key in etcd..."
        
        # Check if the initialize key exists
        if /usr/local/bin/etcdctl get /service/proposalsapp/initialize > /dev/null 2>&1; then
          init_value=$(/usr/local/bin/etcdctl get /service/proposalsapp/initialize --print-value-only)
          echo "Found initialize value in etcd: $init_value"
          exit 0
        else
          echo "ERROR: No initialize key found in etcd"
          exit 1
        fi
      args:
        executable: /bin/bash
      register: etcd_init_check
      until: etcd_init_check.rc == 0
      retries: 60
      delay: 5
      run_once: true

    - name: Verify initialize key is available in etcd before starting standby
      shell: |
        export ETCDCTL_API=3
        
        # Check if the initialize key exists in etcd
        if /usr/local/bin/etcdctl get /service/proposalsapp/initialize > /dev/null 2>&1; then
          init_value=$(/usr/local/bin/etcdctl get /service/proposalsapp/initialize --print-value-only)
          echo "Found initialize value in etcd: $init_value"
          exit 0
        else
          echo "ERROR: Initialize key not found in etcd"
          exit 1
        fi
      register: etcd_init_check_standby
      until: etcd_init_check_standby.rc == 0
      retries: 90
      delay: 5
      when: postgres_role != 'primary'

    - name: Start Patroni on standby nodes
      systemd:
        name: patroni
        state: started
        enabled: yes
      when: postgres_role != 'primary'

    - name: Wait for all nodes to stabilize
      pause:
        seconds: 30
      run_once: true

    - name: Verify cluster has formed with leader
      shell: |
        # Check for leader in the cluster
        i=1
        while [ $i -le 30 ]; do
          if /var/lib/postgresql/.local/bin/patronictl -c /etc/patroni/patroni.yml list 2>&1 | grep -q "Leader"; then
            echo "Cluster has a leader"
            /var/lib/postgresql/.local/bin/patronictl -c /etc/patroni/patroni.yml list
            exit 0
          fi
          sleep 2
          i=$((i + 1))
        done
        echo "ERROR: No leader elected"
        exit 1
      run_once: true
      delegate_to: db-sib-01  # Check from primary DC
      register: leader_check

    - name: Wait for all nodes to join cluster
      shell: |
        # Wait for this node to appear in the cluster
        i=1
        while [ $i -le 90 ]; do
          cluster_output=$(/var/lib/postgresql/.local/bin/patronictl -c /etc/patroni/patroni.yml list 2>&1)
          
          # Check if this node appears in the cluster output
          if echo "$cluster_output" | grep -q "{{ inventory_hostname }}"; then
            # Also check if the node is in a good state (running or streaming)
            if echo "$cluster_output" | grep "{{ inventory_hostname }}" | grep -qE "(running|streaming)"; then
              echo "Node joined cluster successfully and is in good state"
              echo "$cluster_output"
              exit 0
            else
              echo "Node is in cluster but not yet in good state, waiting... (attempt $i/90)"
            fi
          else
            echo "Waiting for node to join cluster... (attempt $i/90)"
          fi
          sleep 2
          i=$((i + 1))
        done
        echo "ERROR: Failed to join cluster or reach good state after 180 seconds"
        echo "Final Patroni status:"
        /var/lib/postgresql/.local/bin/patronictl -c /etc/patroni/patroni.yml list 2>&1 || true
        echo ""
        echo "Patroni service status:"
        systemctl status patroni --no-pager || true
        echo ""
        echo "Last 50 lines of Patroni log:"
        journalctl -u patroni -n 50 --no-pager || true
        exit 1
      register: node_join
      failed_when: node_join.rc != 0

    - name: Check if PostgreSQL service is already registered
      uri:
        url: "http://localhost:{{ consul_client_port }}/v1/agent/service/postgres-{{ inventory_hostname }}"
        method: GET
        status_code: [200, 404]
      register: postgres_service_check
      changed_when: false

    - name: Register PostgreSQL services in Consul
      uri:
        url: "http://localhost:{{ consul_client_port }}/v1/agent/service/register"
        method: PUT
        body_format: json
        body:
          ID: "postgres-{{ inventory_hostname }}"
          Name: "postgres"
          Tags:
            - "{{ postgres_role }}"
            - "{{ datacenter }}"
          Port: 5432
          Check:
            TCP: "localhost:5432"
            Interval: "10s"
      when: postgres_service_check.status == 404

    - name: Wait for PostgreSQL to be ready
      wait_for:
        port: 5432
        host: localhost
        delay: 5
        timeout: 60


    - name: Store PostgreSQL connection details in Consul KV (primary DC)
      uri:
        url: "http://localhost:{{ consul_client_port }}/v1/kv/{{ item.key }}"
        method: PUT
        body: "{{ item.value }}"
      loop:
        - { key: "postgresql/primary_host", value: "{{ inventory_hostname }}" }
        - { key: "postgresql/primary_tailscale_ip", value: "{{ tailscale_ip }}" }
        - { key: "postgresql/port", value: "5432" }
        - { key: "postgresql/database", value: "{{ postgres_db_name }}" }
        - { key: "postgresql/username", value: "proposalsapp" }
        - { key: "postgresql/admin_username", value: "{{ postgres_user }}" }
        - { key: "postgresql/password", value: "{{ postgres_password }}" }
        - { key: "postgresql/service_discovery", value: "proposalsapp.service.consul" }
        - { key: "postgresql/connection_string/consul", value: "postgresql://proposalsapp:{{ postgres_password }}@proposalsapp.service.consul:5432/{{ postgres_db_name }}" }
        - { key: "postgresql/connection_string/hostname", value: "postgresql://proposalsapp:{{ postgres_password }}@{{ inventory_hostname }}:5432/{{ postgres_db_name }}" }
        - { key: "postgresql/connection_string/tailscale_ip", value: "postgresql://proposalsapp:{{ postgres_password }}@{{ tailscale_ip }}:5432/{{ postgres_db_name }}" }
        - { key: "database/name", value: "{{ postgres_db_name }}" }
        - { key: "database/user", value: "proposalsapp" }
        - { key: "database/password", value: "{{ postgres_password }}" }
      run_once: true
      when: postgres_role == 'primary'

    # Store PostgreSQL connection details in all Consul datacenters
    - name: Store connection details in dc1 Consul
      uri:
        url: "http://{{ hostvars['consul-nomad-sib-01'].tailscale_ip }}:{{ consul_client_port }}/v1/kv/{{ item.key }}"
        method: PUT
        body: "{{ item.value }}"
      loop:
        - { key: "postgresql/primary_host", value: "{{ inventory_hostname }}" }
        - { key: "postgresql/primary_tailscale_ip", value: "{{ tailscale_ip }}" }
        - { key: "postgresql/port", value: "5432" }
        - { key: "postgresql/database", value: "{{ postgres_db_name }}" }
        - { key: "postgresql/username", value: "proposalsapp" }
        - { key: "postgresql/admin_username", value: "{{ postgres_user }}" }
        - { key: "postgresql/password", value: "{{ postgres_password }}" }
        - { key: "postgresql/service_discovery", value: "proposalsapp.service.consul" }
        - { key: "postgresql/connection_string/consul", value: "postgresql://proposalsapp:{{ postgres_password }}@proposalsapp.service.consul:5432/{{ postgres_db_name }}" }
        - { key: "postgresql/connection_string/hostname", value: "postgresql://proposalsapp:{{ postgres_password }}@{{ inventory_hostname }}:5432/{{ postgres_db_name }}" }
        - { key: "postgresql/connection_string/tailscale_ip", value: "postgresql://proposalsapp:{{ postgres_password }}@{{ tailscale_ip }}:5432/{{ postgres_db_name }}" }
        - { key: "database/name", value: "{{ postgres_db_name }}" }
        - { key: "database/user", value: "proposalsapp" }
        - { key: "database/password", value: "{{ postgres_password }}" }
      delegate_to: "{{ inventory_hostname }}"
      when: postgres_role == 'primary'

    - name: Store connection details in dc2 Consul
      uri:
        url: "http://{{ hostvars['consul-nomad-sib-03'].tailscale_ip }}:{{ consul_client_port }}/v1/kv/{{ item.key }}"
        method: PUT
        body: "{{ item.value }}"
      loop:
        - { key: "postgresql/primary_host", value: "{{ inventory_hostname }}" }
        - { key: "postgresql/primary_tailscale_ip", value: "{{ tailscale_ip }}" }
        - { key: "postgresql/port", value: "5432" }
        - { key: "postgresql/database", value: "{{ postgres_db_name }}" }
        - { key: "postgresql/username", value: "proposalsapp" }
        - { key: "postgresql/admin_username", value: "{{ postgres_user }}" }
        - { key: "postgresql/password", value: "{{ postgres_password }}" }
        - { key: "postgresql/service_discovery", value: "proposalsapp.service.consul" }
        - { key: "postgresql/connection_string/consul", value: "postgresql://proposalsapp:{{ postgres_password }}@proposalsapp.service.consul:5432/{{ postgres_db_name }}" }
        - { key: "postgresql/connection_string/hostname", value: "postgresql://proposalsapp:{{ postgres_password }}@{{ inventory_hostname }}:5432/{{ postgres_db_name }}" }
        - { key: "postgresql/connection_string/tailscale_ip", value: "postgresql://proposalsapp:{{ postgres_password }}@{{ tailscale_ip }}:5432/{{ postgres_db_name }}" }
        - { key: "database/name", value: "{{ postgres_db_name }}" }
        - { key: "database/user", value: "proposalsapp" }
        - { key: "database/password", value: "{{ postgres_password }}" }
      delegate_to: "{{ inventory_hostname }}"
      when: postgres_role == 'primary'

    - name: Store connection details in dc3 Consul
      uri:
        url: "http://{{ hostvars['consul-nomad-fsn-01'].tailscale_ip }}:{{ consul_client_port }}/v1/kv/{{ item.key }}"
        method: PUT
        body: "{{ item.value }}"
      loop:
        - { key: "postgresql/primary_host", value: "{{ inventory_hostname }}" }
        - { key: "postgresql/primary_tailscale_ip", value: "{{ tailscale_ip }}" }
        - { key: "postgresql/port", value: "5432" }
        - { key: "postgresql/database", value: "{{ postgres_db_name }}" }
        - { key: "postgresql/username", value: "proposalsapp" }
        - { key: "postgresql/admin_username", value: "{{ postgres_user }}" }
        - { key: "postgresql/password", value: "{{ postgres_password }}" }
        - { key: "postgresql/service_discovery", value: "proposalsapp.service.consul" }
        - { key: "postgresql/connection_string/consul", value: "postgresql://proposalsapp:{{ postgres_password }}@proposalsapp.service.consul:5432/{{ postgres_db_name }}" }
        - { key: "postgresql/connection_string/hostname", value: "postgresql://proposalsapp:{{ postgres_password }}@{{ inventory_hostname }}:5432/{{ postgres_db_name }}" }
        - { key: "postgresql/connection_string/tailscale_ip", value: "postgresql://proposalsapp:{{ postgres_password }}@{{ tailscale_ip }}:5432/{{ postgres_db_name }}" }
        - { key: "database/name", value: "{{ postgres_db_name }}" }
        - { key: "database/user", value: "proposalsapp" }
        - { key: "database/password", value: "{{ postgres_password }}" }
      delegate_to: "{{ inventory_hostname }}"
      when: postgres_role == 'primary'

    - name: Wait for all PostgreSQL nodes to join cluster
      pause:
        seconds: 45
      run_once: true

    - name: Verify all nodes are in cluster before configuring replication
      shell: |
        # Get the expected number of nodes
        expected_nodes="{{ groups['postgres_nodes'] | length }}"
        
        # Count actual nodes in cluster
        actual_nodes=$(/var/lib/postgresql/.local/bin/patronictl -c /etc/patroni/patroni.yml list | grep -E "Leader|Replica" | wc -l)
        
        echo "Expected nodes: $expected_nodes, Actual nodes: $actual_nodes"
        
        # Accept if we have at least 2 nodes (primary + 1 replica) for quorum
        if [ "$actual_nodes" -ge 2 ]; then
          echo "Minimum required nodes are in the cluster (have $actual_nodes, need at least 2)"
          exit 0
        elif [ "$actual_nodes" -eq "$expected_nodes" ]; then
          echo "All nodes are in the cluster"
          exit 0
        else
          echo "WARNING: Not enough nodes have joined the cluster yet"
          exit 1
        fi
      register: cluster_check
      until: cluster_check.rc == 0
      retries: 20
      delay: 15
      when: postgres_role == 'primary'
      run_once: true

    - name: Verify Patroni is using etcd for DCS
      shell: |
        export ETCDCTL_API=3
        # Wait a bit for keys to be created
        for i in {1..10}; do
          if /usr/local/bin/etcdctl get /service/proposalsapp --prefix | grep -q -E "(initialize|members|leader|config)"; then
            echo "SUCCESS: Patroni is using etcd for cluster coordination"
            echo "Keys found in etcd:"
            /usr/local/bin/etcdctl get /service/proposalsapp --prefix --keys-only | head -10
            
            # Also verify no DCS keys in Consul (service registration is OK)
            consul_keys=$(curl -s http://localhost:8500/v1/kv/service/proposalsapp?recurse 2>/dev/null || echo "[]")
            if [ "$consul_keys" != "[]" ] && [ -n "$consul_keys" ]; then
              echo "WARNING: Found Patroni DCS keys in Consul - this should not happen!"
              echo "$consul_keys"
              exit 1
            fi
            exit 0
          fi
          echo "Waiting for Patroni to create keys in etcd... (attempt $i/10)"
          sleep 3
        done
        echo "ERROR: Patroni is not using etcd - no keys found after 30 seconds"
        exit 1
      register: etcd_verify
      run_once: true
      failed_when: false  # We'll check the result manually

    - name: Check etcd verification result
      fail:
        msg: "{{ etcd_verify.stdout }}"
      when: etcd_verify.rc != 0

    - name: Configure synchronous replication with proper standby names
      shell: |
        # Get list of standby nodes from the cluster
        standby_nodes=$(/var/lib/postgresql/.local/bin/patronictl -c /etc/patroni/patroni.yml list | grep "Replica" | awk '{print $2}' | tr '\n' ',' | sed 's/,$//')
        
        if [ -n "$standby_nodes" ]; then
          echo "Found standby nodes: $standby_nodes"
          
          # Count replicas
          replica_count=$(echo "$standby_nodes" | tr ',' '\n' | wc -l)
          
          # Build synchronous_standby_names based on datacenter distribution
          # Use ANY 1 syntax for quorum-based replication
          sync_standby_names="ANY 1 ($standby_nodes)"
          
          echo "Enabling synchronous replication with: $sync_standby_names"
          
          # Enable synchronous mode in Patroni
          /var/lib/postgresql/.local/bin/patronictl -c /etc/patroni/patroni.yml edit-config \
            -s "synchronous_mode=true" \
            -s "synchronous_mode_strict=false" \
            -s "postgresql.parameters.synchronous_commit=remote_apply" \
            -s "postgresql.parameters.synchronous_standby_names='$sync_standby_names'" \
            --force
          
          echo "Synchronous replication enabled with $replica_count replicas"
        else
          echo "No replicas found, keeping synchronous mode disabled"
          
          # Ensure async parameters are set
          /var/lib/postgresql/.local/bin/patronictl -c /etc/patroni/patroni.yml edit-config \
            -s "synchronous_mode=false" \
            -s "postgresql.parameters.synchronous_commit=on" \
            -s "postgresql.parameters.synchronous_standby_names=" \
            --force
        fi
      register: sync_result
      changed_when: "'Synchronous replication enabled' in sync_result.stdout"
      run_once: true
      when: postgres_role == 'primary'

    - name: Wait for database initialization to complete
      pause:
        seconds: 10
      when: postgres_role == 'primary'

    - name: Check if this node is the leader
      shell: |
        /var/lib/postgresql/.local/bin/patronictl -c /etc/patroni/patroni.yml list | grep "{{ inventory_hostname }}" | grep -q "Leader"
      register: is_leader
      failed_when: false
      changed_when: false

    - name: Create application database on leader node
      shell: |
        export PGPASSWORD="{{ postgres_password }}"
        
        # First check if we can connect as postgres user
        if ! psql -h localhost -U postgres -d postgres -c "SELECT 1;" >/dev/null 2>&1; then
          echo "ERROR: Cannot connect to PostgreSQL as postgres user"
          exit 1
        fi
        
        # Ensure proposalsapp role exists before creating database
        if ! psql -h localhost -U postgres -d postgres -tAc "SELECT 1 FROM pg_roles WHERE rolname='proposalsapp';" | grep -q 1; then
          echo "Creating proposalsapp role first..."
          psql -h localhost -U postgres -d postgres -c "CREATE ROLE proposalsapp WITH LOGIN PASSWORD '{{ postgres_password }}' CREATEDB CREATEROLE;"
        fi
        
        # Check if database already exists
        if psql -h localhost -U postgres -d postgres -tAc "SELECT 1 FROM pg_database WHERE datname='proposalsapp';" | grep -q 1; then
          echo "Database proposalsapp already exists"
          # Ensure proposalsapp can connect
          export PGPASSWORD="{{ postgres_password }}"
          if psql -h localhost -U proposalsapp -d proposalsapp -c "SELECT 1;" >/dev/null 2>&1; then
            echo "Database exists and is accessible"
            exit 0
          else
            echo "Database exists but proposalsapp cannot connect, granting permissions..."
            export PGPASSWORD="{{ postgres_password }}"
            psql -h localhost -U postgres -d proposalsapp -c "GRANT ALL PRIVILEGES ON DATABASE proposalsapp TO proposalsapp;"
            psql -h localhost -U postgres -d proposalsapp -c "GRANT ALL ON SCHEMA public TO proposalsapp;"
          fi
        else
          # Create the database
          echo "Creating database proposalsapp..."
          psql -h localhost -U postgres -c "CREATE DATABASE proposalsapp OWNER proposalsapp ENCODING 'UTF8';"
        fi
        
        # Verify connection as proposalsapp user
        export PGPASSWORD="{{ postgres_password }}"
        if ! psql -h localhost -U proposalsapp -d proposalsapp -c "SELECT version();" >/dev/null 2>&1; then
          echo "ERROR: Cannot connect as proposalsapp user to new database"
          exit 1
        fi
        
        echo "SUCCESS: Database created and verified"
      when: is_leader.rc == 0  # Only run on the actual leader
      register: db_create
      retries: 5
      delay: 10
      until: db_create.rc == 0

    - name: Deploy PostgreSQL health check script
      template:
        src: ../templates/postgres-health-check.sh.j2
        dest: /usr/local/bin/postgres-health-check
        owner: root
        group: root
        mode: "0755"

    - name: Create systemd timer for health checks
      copy:
        content: |
          [Unit]
          Description=PostgreSQL Health Check Timer
          
          [Timer]
          OnBootSec=5min
          OnUnitActiveSec=5min
          
          [Install]
          WantedBy=timers.target
        dest: /etc/systemd/system/postgres-health-check.timer
        
    - name: Create systemd service for health checks
      copy:
        content: |
          [Unit]
          Description=PostgreSQL Health Check
          After=patroni.service
          
          [Service]
          Type=oneshot
          ExecStart=/usr/local/bin/postgres-health-check
          StandardOutput=journal
          StandardError=journal
        dest: /etc/systemd/system/postgres-health-check.service
        
    - name: Enable and start health check timer
      systemd:
        name: postgres-health-check.timer
        enabled: yes
        state: started
        daemon_reload: yes

    - name: Register PostgreSQL service in Consul
      uri:
        url: "http://localhost:{{ consul_client_port | default(8500) }}/v1/agent/service/register"
        method: PUT
        body_format: json
        body:
          ID: "proposalsapp-{{ inventory_hostname }}"
          Name: "proposalsapp"
          Tags:
            - "{% if is_leader.rc == 0 %}primary{% else %}replica{% endif %}"
            - "postgres"
            - "{{ datacenter }}"
          Address: "{{ tailscale_ip | default(ansible_default_ipv4.address) }}"
          Port: "{{ postgres_port }}"
          Check:
            HTTP: "http://{{ tailscale_ip | default(ansible_default_ipv4.address) }}:{{ patroni_rest_api_port }}/{% if is_leader.rc == 0 %}primary{% else %}replica{% endif %}"
            Interval: "10s"
            DeregisterCriticalServiceAfter: "90s"
      ignore_errors: yes

  handlers:
    - name: reload systemd
      systemd:
        daemon_reload: yes

    - name: restart patroni
      systemd:
        name: patroni
        state: restarted


# Verification checks at the end
- name: Verify PostgreSQL Cluster
  hosts: postgres_nodes
  gather_facts: false
  vars:
    postgres_user: "postgres"
    postgres_db_name: "proposalsapp"
    postgres_password: "{{ vault_postgres_password }}"
    consul_client_port: 8500
  tasks:
    - name: Wait for PostgreSQL to stabilize
      pause:
        seconds: 15

    - name: Check Patroni service health
      shell: |
        # Check if Patroni is running
        if ! systemctl is-active patroni >/dev/null 2>&1; then
          echo "ERROR: Patroni service is not running"
          exit 1
        fi

        echo "OK: Patroni service is active"
      register: patroni_health
      changed_when: false
      failed_when: patroni_health.rc != 0

    - name: Check Patroni cluster status
      shell: |
        # Check Patroni cluster status
        cluster_info=$(/var/lib/postgresql/.local/bin/patronictl -c /etc/patroni/patroni.yml list 2>&1)
        if [ $? -ne 0 ]; then
          echo "ERROR: Cannot query Patroni cluster: $cluster_info"
          exit 1
        fi

        # Check if this node is in the cluster
        if ! echo "$cluster_info" | grep -q "{{ inventory_hostname }}"; then
          # Check if we can at least connect to PostgreSQL
          export PGPASSWORD="{{ postgres_password }}"
          if psql -h localhost -U postgres -c "SELECT 1;" >/dev/null 2>&1; then
            echo "WARNING: Node not visible in Patroni list but PostgreSQL is accessible"
            echo "$cluster_info"
          else
            echo "ERROR: This node is not in the Patroni cluster and PostgreSQL is not accessible"
            echo "$cluster_info"
            exit 1
          fi
        fi

        # Check for a leader (but allow time for election during initial setup)
        if ! echo "$cluster_info" | grep -q -E "(Leader|initializing)"; then
          echo "ERROR: No leader in Patroni cluster and not initializing"
          echo "$cluster_info"
          exit 1
        fi

        echo "OK: Patroni cluster healthy"
        echo "$cluster_info"
      register: patroni_cluster
      changed_when: false
      failed_when: patroni_cluster.rc != 0

    - name: Check PostgreSQL connectivity
      shell: |
        export PGPASSWORD="{{ postgres_password }}"
        if ! psql -h localhost -U {{ postgres_user }} -d postgres -c "SELECT version();" >/dev/null 2>&1; then
          echo "ERROR: Cannot connect to PostgreSQL"
          exit 1
        fi

        echo "OK: PostgreSQL is accessible"
      register: postgres_connectivity
      changed_when: false
      failed_when: postgres_connectivity.rc != 0

    - name: Verify Consul service registration
      shell: |
        # Check if PostgreSQL service is registered in Consul
        service_info=$(curl -s http://localhost:{{ consul_client_port }}/v1/agent/service/postgres-{{ inventory_hostname }})
        if [ $? -ne 0 ] || [ -z "$service_info" ] || [ "$service_info" = "null" ]; then
          echo "ERROR: PostgreSQL service not registered in Consul"
          exit 1
        fi

        echo "OK: PostgreSQL service registered in Consul"
        echo "$service_info" | jq -r '.ID + " - " + .Service + " - Port: " + (.Port|tostring)'
      register: consul_service
      changed_when: false
      failed_when: consul_service.rc != 0

    - name: Verify PostgreSQL connection details in Consul KV
      uri:
        url: "http://localhost:{{ consul_client_port }}/v1/kv/postgresql/connection_string/tailscale_ip?raw"
        method: GET
      register: consul_kv_check
      changed_when: false
      failed_when: false

    - name: Display PostgreSQL verification summary
      debug:
        msg: |
          ========================================
          PostgreSQL Cluster Verification Summary
          ========================================
          Node: {{ inventory_hostname }}
          Patroni Status: {{ 'RUNNING' if patroni_health.rc == 0 else 'FAILED' }}
          Cluster Health: {{ 'HEALTHY' if patroni_cluster.rc == 0 else 'UNHEALTHY' }}
          PostgreSQL Access: {{ 'OK' if postgres_connectivity.rc == 0 else 'FAILED' }}
          Consul Registration: {{ 'REGISTERED' if consul_service.rc == 0 else 'NOT REGISTERED' }}
          Consul KV Data: {{ 'REPLICATED' if consul_kv_check.status == 200 else 'NOT FOUND' }}

          Cluster Status:
          {{ patroni_cluster.stdout | indent(2) }}

          Connection Details:
          - Direct PostgreSQL: {{ inventory_hostname }}:5432
          - Database: {{ postgres_db_name }}
          - Note: Applications should connect via PgCat on localhost:5432
          - User: {{ postgres_user }}
          ========================================

- name: Display Overall Cluster Summary
  hosts: postgres_nodes[0]
  gather_facts: false
  tasks:
    - name: Get full cluster overview
      shell: |
        echo "=== PATRONI CLUSTER OVERVIEW ==="
        patronictl -c /etc/patroni/patroni.yml list
        echo ""
        echo "=== REPLICATION STATUS ==="
        export PGPASSWORD="{{ postgres_password }}"
        psql -h localhost -U {{ postgres_user }} -d postgres -c "SELECT client_addr, state, sync_state FROM pg_stat_replication;" 2>/dev/null || echo "No replicas (this might be a replica node)"
        echo ""
        echo "=== ETCD KEYS (should show Patroni data) ==="
        export ETCDCTL_API=3
        /usr/local/bin/etcdctl get /service/proposalsapp --prefix --keys-only | head -10
      register: cluster_overview
      changed_when: false

    - name: Display cluster overview
      debug:
        msg: |
          ========================================
          PostgreSQL HA Cluster Overview
          ========================================
          {{ cluster_overview.stdout }}
          ========================================
