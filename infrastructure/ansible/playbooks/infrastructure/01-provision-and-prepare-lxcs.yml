---
# This playbook combines container provisioning and base setup into a single operation
# It first creates LXC containers on Proxmox nodes, then prepares them with base packages

- name: Create LXC Containers on Proxmox
  hosts: proxmox_nodes
  gather_facts: true
  pre_tasks:
    - name: Clean all SSH known hosts for containers before provisioning
      shell: |
        # Clean up any old backup files
        rm -f ~/.ssh/known_hosts.old 2>/dev/null || true

        # Remove all container-related entries
        if [ -f ~/.ssh/known_hosts ]; then
          # Remove Tailscale IP range (100.x.x.x)
          grep -v "^100\." ~/.ssh/known_hosts > ~/.ssh/known_hosts.tmp 2>/dev/null || true
          mv ~/.ssh/known_hosts.tmp ~/.ssh/known_hosts 2>/dev/null || true

          # Remove container network range (10.10.x.x)
          grep -v "^10\.10\." ~/.ssh/known_hosts > ~/.ssh/known_hosts.tmp 2>/dev/null || true
          mv ~/.ssh/known_hosts.tmp ~/.ssh/known_hosts 2>/dev/null || true

          # Remove known container hostnames
          for host in apps-sib-01 apps-sib-03 apps-fsn-01 consul-nomad-sib-01 consul-nomad-sib-03 consul-nomad-fsn-01 db-sib-01 db-sib-03 db-fsn-01 redis-sib-01 redis-sib-03 redis-fsn-01 github-runner-sib-01 github-runner-sib-03 github-runner-fsn-01 pgbackweb-sib-01; do
            ssh-keygen -f ~/.ssh/known_hosts -R "$host" 2>/dev/null || true
          done
        fi
      delegate_to: localhost
      run_once: true
      changed_when: false
  vars:
    proxmox_credentials:
      sib-01: "{{ vault_proxmox_password_sib01 }}"
      sib-03: "{{ vault_proxmox_password_sib03 }}"
      fsn-01: "{{ vault_proxmox_password_fsn01 }}"
    # Container IDs use schema: 5[dc_id][01-99]
    # dc_id: 1=sib-01(dc1), 2=sib-03(dc2), 3=fsn-01(dc3)
    # Sequential numbering: 01, 02, 03, 04, 05 for each container type
    container_id_base:
      sib-01: 5100 # Will use 5101, 5102, 5103, 5104, 5105
      sib-03: 5200 # Will use 5201, 5202, 5203, 5204, 5205
      fsn-01: 5300 # Will use 5301, 5302, 5303, 5304, 5305
    # Determine bridge based on location
    network_bridge:
      sib-01: sibnet
      sib-03: sibnet
      fsn-01: sibnet
    lxc_defaults:
      consul_nomad:
        cores: 2
        memory: 4096
        swap: 0
        disk: 20
      database:
        cores: 4
        memory: 8192
        swap: 0
        disk: 100
      apps:
        cores: 8
        memory: 32768
        swap: 0
        disk: 50
      redis:
        cores: 4
        memory: 8192
        swap: 0
        disk: 30
      github_runner:
        cores: 8
        memory: 16384
        swap: 0
        disk: 100
      github_runner_sib: # Double resources for Sibiu runners
        cores: 16
        memory: 32768
        swap: 0
        disk: 100
      pgbackweb:
        cores: 2
        memory: 4096
        swap: 0
        disk: 200
  tasks:
    - name: Install Python3 and pip
      apt:
        name:
          - python3
          - python3-pip
        state: present
        update_cache: yes

    - name: Get list of existing containers
      shell: "pct list | awk 'NR>1 {print $1}' | sort -n"
      register: existing_containers
      changed_when: false

    - name: Set container IDs based on hostname
      set_fact:
        my_containers: "{{ base_containers + (pgbackweb_container if inventory_hostname == 'sib-01' else []) }}"
      vars:
        base_containers:
          - name: "consul-nomad-{{ inventory_hostname }}"
            id: "{{ container_id_base[inventory_hostname] + 1 }}"
            type: consul_nomad
          - name: "db-{{ inventory_hostname }}"
            id: "{{ container_id_base[inventory_hostname] + 2 }}"
            type: database
          - name: "apps-{{ inventory_hostname }}"
            id: "{{ container_id_base[inventory_hostname] + 3 }}"
            type: apps
          - name: "github-runner-{{ inventory_hostname }}"
            id: "{{ container_id_base[inventory_hostname] + 4 }}"
            type: "{{ 'github_runner_sib' if inventory_hostname in ['sib-01', 'sib-03'] else 'github_runner' }}"
          - name: "redis-{{ inventory_hostname }}"
            id: "{{ container_id_base[inventory_hostname] + 5 }}"
            type: redis
        pgbackweb_container:
          - name: "pgbackweb-{{ inventory_hostname }}"
            id: "{{ container_id_base[inventory_hostname] + 7 }}"
            type: pgbackweb

    - name: Check if our containers exist
      shell: "pct list | grep -E '^{{ item.id }}\\s' || echo 'not_found'"
      register: container_exists
      loop: "{{ my_containers }}"
      changed_when: false

    - name: Create containers
      shell: |
        pct create {{ item.0.id }} \
          local:vztmpl/debian-12-standard_12.7-1_amd64.tar.zst \
          --hostname {{ item.0.name }} \
          --cores {{ lxc_defaults[item.0.type].cores }} \
          --memory {{ lxc_defaults[item.0.type].memory }} \
          --swap {{ lxc_defaults[item.0.type].swap }} \
          --rootfs zfs-ssd-m2:{{ lxc_defaults[item.0.type].disk }} \
          --net0 name=eth0,bridge={{ network_bridge[inventory_hostname] }},firewall=1,ip=dhcp,type=veth \
          --nameserver 8.8.8.8 \
          --features nesting=1,fuse=1 \
          --unprivileged 1 \
          --onboot 1 \
          --ssh-public-keys /root/.ssh/authorized_keys \
          --start 0 || { echo "Failed to create container {{ item.0.id }}"; exit 1; }
      when: "'not_found' in item.1.stdout"
      loop: "{{ my_containers | zip(container_exists.results) | list }}"
      register: container_created

    - name: Configure Tailscale /dev/tun access in containers
      shell: |
        echo "Configuring /dev/tun for container {{ item.0.id }}..."

        # For unprivileged containers, we need different device permissions
        if ! grep -q 'lxc.cgroup2.devices.allow: c 10:200 rwm' /etc/pve/lxc/{{ item.0.id }}.conf; then
          echo 'lxc.cgroup2.devices.allow: c 10:200 rwm' >> /etc/pve/lxc/{{ item.0.id }}.conf
          echo 'Added cgroup2 device access'
        else
          echo 'cgroup2 device access already configured'
        fi

        if ! grep -q 'lxc.mount.entry: /dev/net/tun dev/net/tun none bind,create=file' /etc/pve/lxc/{{ item.0.id }}.conf; then
          echo 'lxc.mount.entry: /dev/net/tun dev/net/tun none bind,create=file' >> /etc/pve/lxc/{{ item.0.id }}.conf
          echo 'Added mount entry for /dev/net/tun'
        else
          echo 'Mount entry already configured'
        fi

        # Add ID mapping for unprivileged containers
        if ! grep -q 'lxc.idmap' /etc/pve/lxc/{{ item.0.id }}.conf; then
          echo 'lxc.idmap: u 0 100000 65536' >> /etc/pve/lxc/{{ item.0.id }}.conf
          echo 'lxc.idmap: g 0 100000 65536' >> /etc/pve/lxc/{{ item.0.id }}.conf
        fi

        echo "Current config:"
        grep -E '(cgroup2.devices.allow|mount.entry.*tun)' /etc/pve/lxc/{{ item.0.id }}.conf || echo "No tun config found!"
      when: "'not_found' in item.1.stdout"
      loop: "{{ my_containers | zip(container_exists.results) | list }}"
      register: tun_config

    - name: Configure GPU passthrough for eligible containers
      when: 
        - gpu_enabled_hosts[inventory_hostname] | default(false)
        - item.0.name in gpu_passthrough_containers
      shell: |
        echo "Configuring GPU passthrough for container {{ item.0.id }} ({{ item.0.name }})..."
        
        # Get device numbers from host facts - ensure variables are set even if devices do not exist yet
        if [ -e /dev/nvidiactl ]; then
          hex_val=$(stat -c '%t' /dev/nvidiactl)
          nvidia_major=$(printf "%d" 0x"$hex_val")
        else
          nvidia_major="195"
        fi
        
        if [ -e /dev/nvidia-caps/nvidia-cap1 ]; then
          hex_val=$(stat -c '%t' /dev/nvidia-caps/nvidia-cap1)
          nvidia_caps_major=$(printf "%d" 0x"$hex_val")
        else
          nvidia_caps_major="234"
        fi
        
        if [ -e /dev/nvidia-uvm ]; then
          hex_val=$(stat -c '%t' /dev/nvidia-uvm)
          nvidia_uvm_major=$(printf "%d" 0x"$hex_val")
        else
          nvidia_uvm_major="509"
        fi
        
        if [ -e /dev/nvidia-modeset ]; then
          hex_val=$(stat -c '%t' /dev/nvidia-modeset)
          nvidia_modeset_major=$(printf "%d" 0x"$hex_val")
        else
          nvidia_modeset_major="237"
        fi
        
        if [ -e /dev/dri/card0 ]; then
          hex_val=$(stat -c '%t' /dev/dri/card0)
          dri_major=$(printf "%d" 0x"$hex_val")
        else
          dri_major="226"
        fi
        
        echo "Device majors detected:"
        echo "  nvidia: $nvidia_major"
        echo "  nvidia-caps: $nvidia_caps_major"  
        echo "  nvidia-uvm: $nvidia_uvm_major"
        echo "  nvidia-modeset: $nvidia_modeset_major"
        echo "  dri: $dri_major"
        
        # Validate that we have valid device numbers
        if [ -z "$nvidia_major" ] || [ "$nvidia_major" = "" ]; then
          echo "ERROR: Failed to detect nvidia device major number"
          nvidia_major="195"
        fi
        if [ -z "$dri_major" ] || [ "$dri_major" = "" ]; then
          echo "ERROR: Failed to detect DRI device major number"
          dri_major="226"
        fi
        
        # Check if GPU configuration already exists
        if grep -q "# GPU Passthrough Configuration" /etc/pve/lxc/{{ item.0.id }}.conf; then
          echo "GPU passthrough already configured"
        else
          # Dynamically detect available GPU devices
          # IMPORTANT: LXC config does NOT support shell expansion like {0..3}
          # Each device must have its own mount entry line
          gpu_devices=""
          
          # Find all nvidia GPU devices (nvidia0, nvidia1, etc.)
          for device in $(ls -1 /dev/nvidia* 2>/dev/null | grep -E 'nvidia[0-9]+$' || true); do
            device_name=$(basename "$device")
            if [ -n "$gpu_devices" ]; then
              gpu_devices="${gpu_devices}\n"
            fi
            gpu_devices="${gpu_devices}lxc.mount.entry: $device dev/$device_name none bind,optional,create=file"
          done
          
          # If no GPU devices found, detect the number of GPUs from nvidia-smi and create entries
          if [ -z "$gpu_devices" ]; then
            gpu_count=$(nvidia-smi --query-gpu=count --format=csv,noheader 2>/dev/null | head -1 || echo "0")
            if [ "$gpu_count" -gt 0 ]; then
              for i in $(seq 0 $((gpu_count - 1))); do
                if [ -n "$gpu_devices" ]; then
                  gpu_devices="${gpu_devices}\n"
                fi
                gpu_devices="${gpu_devices}lxc.mount.entry: /dev/nvidia$i dev/nvidia$i none bind,optional,create=file"
              done
            fi
          fi
          
          # Add GPU passthrough configuration
          {
            echo ""
            echo "# GPU Passthrough Configuration"
            echo "# Device permissions"
            echo "lxc.cgroup2.devices.allow: c ${nvidia_major}:* rwm"
            echo "lxc.cgroup2.devices.allow: c ${dri_major}:* rwm"
            echo ""
            echo "# nvidia-uvm can be 507-511, allow all"
            echo "lxc.cgroup2.devices.allow: c 507:* rwm"
            echo "lxc.cgroup2.devices.allow: c 508:* rwm"
            echo "lxc.cgroup2.devices.allow: c 509:* rwm"
            echo "lxc.cgroup2.devices.allow: c 510:* rwm"
            echo "lxc.cgroup2.devices.allow: c 511:* rwm"
            echo ""
            echo "# nvidia-caps can be 234-235"
            echo "lxc.cgroup2.devices.allow: c 234:* rwm"
            echo "lxc.cgroup2.devices.allow: c 235:* rwm"
            echo ""
            echo "# nvidia-modeset if present"
            echo "lxc.cgroup2.devices.allow: c ${nvidia_modeset_major}:* rwm"
            echo ""
            echo "# Mount NVIDIA GPU devices"
            echo -e "$gpu_devices"
            echo "# Mount NVIDIA control devices"
            echo "lxc.mount.entry: /dev/nvidiactl dev/nvidiactl none bind,optional,create=file"
            echo "lxc.mount.entry: /dev/nvidia-modeset dev/nvidia-modeset none bind,optional,create=file"
            echo "lxc.mount.entry: /dev/nvidia-uvm dev/nvidia-uvm none bind,optional,create=file"
            echo "lxc.mount.entry: /dev/nvidia-uvm-tools dev/nvidia-uvm-tools none bind,optional,create=file"
            echo ""
            echo "# Mount DRI devices"
            echo "lxc.mount.entry: /dev/dri dev/dri none bind,optional,create=dir"
            echo ""
            echo "# Mount nvidia-caps"
            echo "lxc.mount.entry: /dev/nvidia-caps dev/nvidia-caps none bind,optional,create=dir"
            echo ""
            echo "# Additional GPU-related mounts"
            echo "lxc.mount.entry: /usr/lib/x86_64-linux-gnu/nvidia usr/lib/x86_64-linux-gnu/nvidia none bind,optional,create=dir"
          } >> /etc/pve/lxc/{{ item.0.id }}.conf
          echo "GPU passthrough configuration added"
        fi
        
        # Display final GPU configuration
        echo "GPU configuration in container:"
        grep -A 20 "# GPU Passthrough Configuration" /etc/pve/lxc/{{ item.0.id }}.conf
      loop: "{{ my_containers | zip(container_exists.results) | list }}"
      register: gpu_config

    - name: Ensure GPU devices are properly configured
      when: 
        - gpu_enabled_hosts[inventory_hostname] | default(false)
        - item.name in gpu_passthrough_containers
      block:
        - name: Find all NVIDIA GPU devices
          find:
            paths: /dev
            patterns: 'nvidia[0-9]+$'
            use_regex: yes
            file_type: any
          register: gpu_device_files

        - name: Verify GPU mount entries are correct
          shell: |
            config_file="/etc/pve/lxc/{{ item.id }}.conf"
            
            # Check each found GPU device
            {% for device in gpu_device_files.files | default([]) %}
            device_name="{{ device.path | basename }}"
            if ! grep -q "lxc.mount.entry: {{ device.path }} dev/$device_name" "$config_file"; then
              echo "Missing mount entry for {{ device.path }}"
              # Add the missing entry after the GPU devices comment
              sed -i '/# Mount NVIDIA GPU devices/a lxc.mount.entry: {{ device.path }} dev/{{ device.path | basename }} none bind,optional,create=file' "$config_file"
            fi
            {% endfor %}
            
            echo "GPU mount entries verified"
          loop: "{{ my_containers }}"
          when: gpu_device_files.files is defined and gpu_device_files.files | length > 0

    - name: GPU host preparation
      when: gpu_enabled_hosts[inventory_hostname] | default(false)
      block:
        - name: Ensure kernel headers are installed
          apt:
            name:
              - linux-headers-amd64
              - pve-headers
            state: present
            update_cache: yes
          ignore_errors: true

        - name: Check secure boot status
          shell: |
            if command -v mokutil &>/dev/null; then
              mokutil --sb-state 2>/dev/null || echo "SecureBoot not supported"
            else
              echo "mokutil not found - SecureBoot check skipped"
            fi
          register: secure_boot_status
          changed_when: false

        - name: Fail if Secure Boot is enabled
          fail:
            msg: |
              ❌ ERROR: Secure Boot is enabled!
              NVIDIA drivers will NOT work with Secure Boot enabled unless properly signed.
              Please disable Secure Boot and re-run this playbook.
          when: "'SecureBoot enabled' in secure_boot_status.stdout"

        - name: Install GPU support packages
          apt:
            name:
              - build-essential
              - dkms
              - pve-headers-{{ ansible_kernel }}
              - wget
              - libglvnd-dev
              - pkg-config
              - mokutil
            state: present
            update_cache: yes

        - name: Blacklist nouveau driver
          copy:
            content: |
              # Only blacklist nouveau for NVIDIA driver
              # DO NOT blacklist nvidia drivers for LXC passthrough!
              blacklist nouveau
              options nouveau modeset=0
            dest: /etc/modprobe.d/blacklist-nouveau.conf
            mode: '0644'

        - name: Check if NVIDIA driver is installed
          stat:
            path: /usr/bin/nvidia-smi
          register: nvidia_driver_check

        - name: Add NVIDIA CUDA repository key
          apt_key:
            url: https://developer.download.nvidia.com/compute/cuda/repos/debian12/x86_64/3bf863cc.pub
            state: present
          when: not nvidia_driver_check.stat.exists

        - name: Add NVIDIA CUDA repository  
          apt_repository:
            repo: "deb https://developer.download.nvidia.com/compute/cuda/repos/debian12/x86_64/ /"
            state: present
            filename: cuda-debian12
          when: not nvidia_driver_check.stat.exists

        - name: Install NVIDIA driver from CUDA repository
          apt:
            name:
              - cuda-drivers
              - nvidia-settings
              - nvidia-modprobe
              - nvidia-persistenced
            state: present
            update_cache: yes
          when: not nvidia_driver_check.stat.exists
          register: nvidia_driver_install
          retries: 2
          delay: 10
          until: nvidia_driver_install is success

        - name: Create NVIDIA device nodes script
          copy:
            content: |
              #!/bin/bash
              # Script to create NVIDIA device nodes if they don't exist
              
              # Load modules if not loaded
              modprobe nvidia 2>/dev/null || true
              modprobe nvidia-uvm 2>/dev/null || true
              
              # Wait for modules to initialize
              sleep 2
              
              # Create nvidia-uvm devices if missing
              if [ ! -e /dev/nvidia-uvm ]; then
                major=$(grep nvidia-uvm /proc/devices | cut -d ' ' -f 1)
                if [ -n "$major" ]; then
                  mknod -m 666 /dev/nvidia-uvm c $major 0
                  mknod -m 666 /dev/nvidia-uvm-tools c $major 1
                fi
              fi
              
              # Create nvidia-modeset device if missing
              if [ ! -e /dev/nvidia-modeset ]; then
                major=$(grep nvidia-modeset /proc/devices | cut -d ' ' -f 1)
                if [ -n "$major" ]; then
                  mknod -m 666 /dev/nvidia-modeset c $major 0
                fi
              fi
              
              # Create nvidia-caps directory and devices
              mkdir -p /dev/nvidia-caps
              nvidia_caps_major=$(grep nvidia-caps /proc/devices | cut -d ' ' -f 1)
              if [ -n "$nvidia_caps_major" ]; then
                for i in {1..10}; do
                  if [ ! -e /dev/nvidia-caps/nvidia-cap$i ]; then
                    mknod -m 666 /dev/nvidia-caps/nvidia-cap$i c $nvidia_caps_major $i 2>/dev/null || true
                  fi
                done
              fi
              
              # Set permissions
              chmod 666 /dev/nvidia* 2>/dev/null || true
              chmod 666 /dev/nvidia-caps/* 2>/dev/null || true
            dest: /usr/local/bin/create-nvidia-devices.sh
            mode: '0755'

        - name: Create systemd service for NVIDIA device creation
          copy:
            content: |
              [Unit]
              Description=Create NVIDIA device nodes
              After=nvidia.service
              
              [Service]
              Type=oneshot
              ExecStart=/usr/local/bin/create-nvidia-devices.sh
              RemainAfterExit=yes
              
              [Install]
              WantedBy=multi-user.target
            dest: /etc/systemd/system/nvidia-devices.service
            mode: '0644'

        - name: Enable NVIDIA device creation service
          systemd:
            name: nvidia-devices.service
            enabled: yes
            daemon_reload: yes
            state: started

        - name: Enable NVIDIA persistence daemon
          systemd:
            name: nvidia-persistenced
            enabled: yes
            state: started
          ignore_errors: true

        - name: Update initramfs if driver was installed
          command: update-initramfs -u -k all
          when: nvidia_driver_install is changed
          ignore_errors: true

        - name: Check for NVIDIA GPU presence
          shell: |
            if lspci | grep -i nvidia > /dev/null 2>&1; then
              echo "nvidia_gpu_found"
            else
              echo "no_nvidia_gpu"
            fi
          register: gpu_check
          changed_when: false

        - name: Display GPU detection result
          debug:
            msg: |
              GPU detection on {{ inventory_hostname }}: {{ gpu_check.stdout }}
              {% if gpu_check.stdout == "no_nvidia_gpu" %}
              Note: No NVIDIA GPU detected. This might be because:
              - The GPU is passed through to a VM
              - The host needs a reboot after driver installation
              - No physical GPU is installed
              {% endif %}
          when: gpu_enabled_hosts[inventory_hostname] | default(false)

        - name: Load NVIDIA kernel modules
          modprobe:
            name: "{{ item }}"
            state: present
          loop:
            - nvidia
            - nvidia-uvm
            - nvidia-modeset
          when: 
            - gpu_enabled_hosts[inventory_hostname] | default(false)
            - gpu_check.stdout == "nvidia_gpu_found"
          ignore_errors: true

        - name: Run NVIDIA device creation script
          command: /usr/local/bin/create-nvidia-devices.sh
          when: 
            - gpu_enabled_hosts[inventory_hostname] | default(false)
            - gpu_check.stdout == "nvidia_gpu_found"
            - nvidia_driver_install is changed or nvidia_driver_check.stat.exists
          ignore_errors: true

    - name: Check container status
      shell: "pct status {{ item.id }} | grep -q 'status: running' && echo 'running' || echo 'stopped'"
      loop: "{{ my_containers }}"
      register: container_status
      changed_when: false

    - name: Start containers
      shell: "pct start {{ item.0.id }}"
      loop: "{{ my_containers | zip(container_status.results) | list }}"
      when: "'stopped' in item.1.stdout"
      register: containers_started
      retries: 3
      delay: 5
      until: containers_started is success
      ignore_errors: true

    - name: Check if any containers failed to start
      shell: "pct status {{ item.id }} | grep -q 'status: running' || echo 'Container {{ item.id }} failed to start'"
      loop: "{{ my_containers }}"
      register: container_start_check
      changed_when: false
      when: containers_started is defined

    - name: Wait for containers to be ready
      pause:
        seconds: 15
      when: container_created.changed or containers_started.changed

    - name: Enable SSH in containers
      shell: |
        pct exec {{ item.id }} -- bash -c "
          # Wait for network
          sleep 5

          # Update package list
          apt-get update

          # Install SSH server and other essentials
          apt-get install -y openssh-server curl

          # Configure SSH
          mkdir -p /root/.ssh
          chmod 700 /root/.ssh

          # Add your SSH key
          echo '{{ lookup('file', '~/.ssh/id_rsa.pub', errors='ignore') }}' > /root/.ssh/authorized_keys
          chmod 600 /root/.ssh/authorized_keys

          # Configure SSH daemon
          sed -i 's/#PermitRootLogin.*/PermitRootLogin yes/' /etc/ssh/sshd_config
          sed -i 's/#PubkeyAuthentication.*/PubkeyAuthentication yes/' /etc/ssh/sshd_config

          # Enable and start SSH
          systemctl enable ssh
          systemctl restart ssh
        "
      loop: "{{ my_containers }}"
      ignore_errors: true
      when: container_created.changed

    - name: Install and start Tailscale in containers
      shell: |
        pct exec {{ item.id }} -- bash -c "
          echo '=== Setting up Tailscale in {{ item.name }} ==='

          # Wait for container to be fully ready
          sleep 5

          # Check if Tailscale is already running and configured
          if systemctl is-active --quiet tailscaled && tailscale status &>/dev/null; then
            echo 'Tailscale is already installed and running'
            echo 'Current status:'
            tailscale ip -4 2>/dev/null || echo 'No IP assigned yet'
            exit 0
          fi

          # Verify /dev/net/tun exists
          echo 'Checking /dev/net/tun...'
          if [ -e /dev/net/tun ]; then
            echo '/dev/net/tun exists and is properly configured'
            ls -la /dev/net/tun
          else
            echo 'ERROR: /dev/net/tun does NOT exist!'
            echo 'This indicates the container was not properly configured.'
            echo 'The container needs to be stopped and restarted with proper TUN configuration.'
            exit 1
          fi

          # Check if Tailscale is already installed
          if ! command -v tailscale &> /dev/null; then
            echo 'Installing Tailscale...'
            curl -fsSL https://tailscale.com/install.sh | sh
          else
            echo 'Tailscale already installed'
          fi

          # Ensure Tailscale uses standard mode (not userspace)
          echo 'Configuring Tailscale for standard mode...'
          if [ -f /etc/default/tailscaled ]; then
            # Remove any userspace mode flags
            sed -i 's/FLAGS=".*--tun=userspace-networking.*"/FLAGS=""/' /etc/default/tailscaled
            # Ensure FLAGS is empty or doesn't contain userspace flag
            if ! grep -q '^FLAGS=""' /etc/default/tailscaled; then
              echo 'FLAGS=""' >> /etc/default/tailscaled
            fi
          else
            # Create the file with empty FLAGS
            echo 'FLAGS=""' > /etc/default/tailscaled
          fi

          # Enable IP forwarding
          if ! grep -q 'net.ipv4.ip_forward=1' /etc/sysctl.conf; then
            echo 'net.ipv4.ip_forward=1' >> /etc/sysctl.conf
          fi
          if ! grep -q 'net.ipv6.conf.all.forwarding=1' /etc/sysctl.conf; then
            echo 'net.ipv6.conf.all.forwarding=1' >> /etc/sysctl.conf
          fi
          sysctl -p

          # Start and enable tailscaled
          echo 'Starting tailscaled...'
          systemctl enable tailscaled
          systemctl start tailscaled

          # Wait for daemon to be ready
          for i in {1..10}; do
            if systemctl is-active --quiet tailscaled; then
              echo 'Tailscale daemon is running'
              break
            fi
            echo 'Waiting for tailscaled to start...'
            sleep 2
          done

          # Verify it's running
          systemctl status tailscaled --no-pager || true

          # Check logs for any errors
          echo -e '\nChecking tailscaled logs for errors...'
          journalctl -u tailscaled -n 20 --no-pager | grep -i error || echo 'No errors in logs'
        "
      loop: "{{ my_containers }}"
      ignore_errors: true
      register: tailscale_install

    - name: Check if Tailscale is already configured
      shell: |
        pct exec {{ item.id }} -- bash -c "
          # Check if already connected and configured
          if tailscale status &>/dev/null && tailscale ip -4 &>/dev/null; then
            echo 'already_configured'
          else
            echo 'needs_configuration'
          fi
        "
      loop: "{{ my_containers }}"
      register: tailscale_status_check
      changed_when: false
      ignore_errors: true

    - name: Configure Tailscale with auth key
      shell: |
        pct exec {{ item.0.id }} -- bash -c "
          echo '=== Configuring Tailscale for {{ item.0.name }} ==='

          # Check if tailscaled is running
          if ! systemctl is-active --quiet tailscaled; then
            echo 'ERROR: tailscaled is not running!'
            systemctl status tailscaled --no-pager
            exit 1
          fi

          # Configure Tailscale with hostname
          echo 'Running: tailscale up --authkey=REDACTED --hostname={{ item.0.name }} --accept-routes'
          tailscale up --authkey={{ vault_tailscale_auth_key }} --hostname={{ item.0.name }} --accept-routes 2>&1

          # Check the result
          echo 'Exit code:' $?
        "
      loop: "{{ my_containers | zip(tailscale_status_check.results) | list }}"
      when:
        - vault_tailscale_auth_key is defined
        - "'needs_configuration' in item.1.stdout"
      register: tailscale_setup

    - name: Wait for Tailscale to connect
      pause:
        seconds: 20
      when:
        - vault_tailscale_auth_key is defined
        - tailscale_setup is defined
        - tailscale_setup.changed

    - name: Verify tailscale0 interface exists
      shell: |
        pct exec {{ item.id }} -- bash -c "
          echo '=== Verifying tailscale0 interface for {{ item.name }} ==='
          
          # Wait for interface to come up
          for i in {1..10}; do
            if ip link show tailscale0 &>/dev/null; then
              echo 'tailscale0 interface exists!'
              ip addr show tailscale0
              exit 0
            fi
            echo 'Waiting for tailscale0 interface... (attempt $i/10)'
            sleep 2
          done
          
          echo 'ERROR: tailscale0 interface not created!'
          echo 'This may indicate Tailscale is running in userspace mode.'
          echo 'Checking tailscaled process flags...'
          ps aux | grep tailscaled | grep -v grep || echo 'tailscaled not running'
          exit 1
        "
      loop: "{{ my_containers }}"
      when: vault_tailscale_auth_key is defined
      register: tailscale_interface_check

    - name: Check Tailscale status in all containers
      shell: |
        pct exec {{ item.id }} -- bash -c "
          echo '=== Tailscale Status for {{ item.name }} ==='
          echo 'Checking if tailscaled is running...'
          systemctl is-active tailscaled || echo 'tailscaled is NOT active'

          echo -e '\nChecking Tailscale status...'
          tailscale status 2>&1 || echo 'Failed to get status'

          echo -e '\nChecking Tailscale IP...'
          tailscale ip -4 2>&1 || echo 'No IP assigned'

          echo -e '\nChecking network interfaces...'
          ip addr show tailscale0 2>&1 || echo 'No tailscale0 interface'

          echo -e '\nChecking if logged in...'
          tailscale status --json 2>/dev/null | jq -r '.BackendState' || echo 'Cannot get backend state'
        "
      loop: "{{ my_containers }}"
      register: tailscale_status
      when: vault_tailscale_auth_key is defined

    - name: Configure DNS for Tailscale hostnames
      shell: |
        pct exec {{ item.id }} -- bash -c "
          # Add tailscale DNS to resolv.conf if not already present
          if ! grep -q '{{ dns_servers.tailscale_magic_dns }}' /etc/resolv.conf; then
            echo 'nameserver {{ dns_servers.tailscale_magic_dns }}' > /etc/resolv.conf.new
            cat /etc/resolv.conf >> /etc/resolv.conf.new
            mv /etc/resolv.conf.new /etc/resolv.conf
          fi
        "
      loop: "{{ my_containers }}"
      when: vault_tailscale_auth_key is defined

    - name: Capture Tailscale IPs for all containers
      shell: |
        pct exec {{ item.id }} -- bash -c "tailscale ip -4 2>/dev/null || echo ''"
      loop: "{{ my_containers }}"
      register: container_tailscale_ips
      when: vault_tailscale_auth_key is defined

    - name: Clean up old known hosts backup
      file:
        path: "~/.ssh/known_hosts.old"
        state: absent
      delegate_to: localhost
      run_once: true

    - name: Remove old SSH known hosts entries for containers
      known_hosts:
        name: "{{ item.name }}"
        state: absent
      loop: "{{ my_containers }}"
      delegate_to: localhost
      run_once: false
      ignore_errors: true

    - name: Create facts directory
      file:
        path: /etc/ansible/facts.d
        state: directory
        mode: "0755"

    - name: Store container information as facts
      copy:
        content: |
          {
            "containers": {
          {% for idx in range(my_containers | length) %}
          {% set container = my_containers[idx] %}
          {% set tailscale_ip = container_tailscale_ips.results[idx].stdout | default('') if container_tailscale_ips is defined else '' %}
              "{{ container.name }}": {
                "id": "{{ container.id }}",
                "hostname": "{{ container.name }}",
                "proxmox_node": "{{ inventory_hostname }}",
                "tailscale_ip": "{{ tailscale_ip | trim }}"
              }{% if not loop.last %},{% endif %}
          {% endfor %}
            }
          }
        dest: /etc/ansible/facts.d/lxc_containers.fact
        mode: "0644"

    - name: Store fresh Tailscale IPs for containers
      set_fact:
        fresh_container_ips: >-
          {%- set ips = {} -%}
          {%- for idx in range(my_containers | length) -%}
            {%- set container = my_containers[idx] -%}
            {%- set tailscale_ip = container_tailscale_ips.results[idx].stdout | default('') | trim if container_tailscale_ips is defined else '' -%}
            {%- set _ = ips.update({container.name: tailscale_ip}) -%}
          {%- endfor -%}
          {{ ips }}
      when: container_tailscale_ips is defined

    - name: Final container information
      debug:
        msg: |
          ========================================
          Container Setup Complete on {{ inventory_hostname }}
          ========================================
          {% for idx in range(my_containers | length) %}
          {% set container = my_containers[idx] %}
          {% set tailscale_ip = container_tailscale_ips.results[idx].stdout | default('') | trim if container_tailscale_ips is defined else '' %}
          {{ container.name }}:
            - Container ID: {{ container.id }}
            - Tailscale hostname: {{ container.name }}
            - Tailscale IP: {{ tailscale_ip if tailscale_ip else 'Not assigned' }}
            - Bridge: {{ network_bridge[inventory_hostname] }}
          {% endfor %}

          {% if vault_tailscale_auth_key is defined %}
          Tailscale has been configured. Containers are accessible via:
          {% for idx in range(my_containers | length) %}
          {% set container = my_containers[idx] %}
          {% set tailscale_ip = container_tailscale_ips.results[idx].stdout | default('') | trim if container_tailscale_ips is defined else '' %}
            ssh root@{{ container.name }} ({{ tailscale_ip if tailscale_ip else 'IP pending' }})
          {% endfor %}
          {% else %}
          WARNING: Tailscale auth key not found in vault!
          Add vault_tailscale_auth_key to your vault file:
          ansible-vault edit group_vars/all/vault.yml --vault-password-file vault-password.txt
          {% endif %}
          ========================================

- name: Update inventory with Tailscale IPs
  hosts: proxmox_nodes
  gather_facts: false
  tasks:
    - name: Read current inventory
      slurp:
        src: "{{ playbook_dir }}/../../inventory.yml"
      register: inventory_content
      delegate_to: localhost
      run_once: true

    - name: Parse inventory
      set_fact:
        inventory_data: "{{ inventory_content.content | b64decode | from_yaml }}"
      delegate_to: localhost
      run_once: true

    - name: Update inventory with Tailscale IPs
      set_fact:
        updated_inventory: |
          {% set inv = inventory_data %}
          {%- for host in groups['proxmox_nodes'] -%}
            {%- if hostvars[host]['container_tailscale_ips'] is defined -%}
              {%- for idx in range(hostvars[host]['my_containers'] | length) -%}
                {%- set container = hostvars[host]['my_containers'][idx] -%}
                {%- set ip = hostvars[host]['container_tailscale_ips']['results'][idx]['stdout'] | default('') | trim -%}
                {%- if ip and container.name in inv.all.children.lxc_containers.hosts -%}
                  {%- set _ = inv.all.children.lxc_containers.hosts[container.name].update({'tailscale_ip': ip}) -%}
                {%- endif -%}
              {%- endfor -%}
            {%- endif -%}
          {%- endfor -%}
          {{ inv | to_nice_yaml(indent=2) }}
      delegate_to: localhost
      run_once: true

    - name: Write updated inventory
      copy:
        content: "{{ updated_inventory }}"
        dest: "{{ playbook_dir }}/../../inventory.yml"
        backup: false
        mode: "0644"
      delegate_to: localhost
      run_once: true

# Now run base setup on all newly created containers
- name: Base Setup for All LXC Containers
  hosts: lxc_containers
  become: true
  gather_facts: false
  tasks:
    - name: Get fresh Tailscale IP from proxmox hosts
      set_fact:
        fresh_ip: "{{ hostvars[proxmox_node]['fresh_container_ips'][inventory_hostname] }}"
      when:
        - hostvars[proxmox_node]['fresh_container_ips'] is defined
        - inventory_hostname in hostvars[proxmox_node]['fresh_container_ips']

    - name: Use fresh Tailscale IP for connection
      set_fact:
        ansible_host: "{{ fresh_ip }}"
      when: fresh_ip is defined and fresh_ip != ''

    - name: Remove old SSH known hosts entries for all containers
      shell: |
        # Remove any existing backup file first
        rm -f ~/.ssh/known_hosts.old 2>/dev/null || true
        # Now remove the host entry
        ssh-keygen -f ~/.ssh/known_hosts -R "{{ item }}" 2>/dev/null || true
      loop:
        - "{{ inventory_hostname }}"
        - "{{ tailscale_ip | default('') }}"
        - "{{ fresh_ip | default('') }}"
        - "{{ ansible_host | default('') }}"
      when: item != ''
      delegate_to: localhost
      become: false
      changed_when: false
      ignore_errors: true # Continue even if ssh-keygen fails

    - name: Wait for container network to be ready
      wait_for:
        host: "{{ ansible_host | default(inventory_hostname) }}"
        port: 22
        delay: 5
        timeout: 120
        state: started
      delegate_to: localhost
      become: false
      register: wait_result
      ignore_errors: true
      
    - name: Skip container if network not ready
      set_fact:
        skip_container: true
      when: wait_result is failed

    - name: Wait for SSH connection
      wait_for_connection:
        delay: 5
        timeout: 180
      when: skip_container is not defined or not skip_container

    - name: Gather facts after connection
      setup:
      when: skip_container is not defined or not skip_container

    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600
      when: skip_container is not defined or not skip_container

    - name: Install base packages
      apt:
        name:
          - curl
          - wget
          - gnupg
          - lsb-release
          - ca-certificates
          - apt-transport-https
          - software-properties-common
          - python3-pip
          - git
          - vim
          - htop
          - net-tools
          - dnsutils
          - jq
          - unzip
          - rsync
        state: present

    - name: Set timezone
      timezone:
        name: UTC

    - name: Configure sysctl for better performance
      sysctl:
        name: "{{ item.name }}"
        value: "{{ item.value }}"
        state: present
        sysctl_set: yes
      loop:
        - { name: "net.ipv4.tcp_keepalive_time", value: "120" }
        - { name: "net.ipv4.ip_forward", value: "1" }
        - { name: "net.bridge.bridge-nf-call-iptables", value: "1" }
        - { name: "net.bridge.bridge-nf-call-ip6tables", value: "1" }

    - name: Create necessary directories
      file:
        path: "{{ item }}"
        state: directory
        mode: "0755"
      loop:
        - /etc/consul
        - /etc/nomad
        - /opt/consul
        - /opt/nomad
        - /var/lib/consul
        - /var/lib/nomad

    - name: Add HashiCorp GPG key
      apt_key:
        url: https://apt.releases.hashicorp.com/gpg
        state: present

    - name: Add HashiCorp repository
      apt_repository:
        repo: "deb [arch=amd64] https://apt.releases.hashicorp.com {{ ansible_distribution_release }} main"
        state: present

    - name: Check if systemd-resolved is available
      stat:
        path: /etc/systemd/resolved.conf
      register: systemd_resolved_check

    - name: Configure systemd-resolved for Consul DNS
      blockinfile:
        path: /etc/systemd/resolved.conf
        block: |
          [Resolve]
          DNS=127.0.0.1
          Domains=~consul
          DNSStubListener=no
      when: systemd_resolved_check.stat.exists
      notify: restart systemd-resolved

    - name: Configure /etc/resolv.conf for Consul DNS (fallback)
      lineinfile:
        path: /etc/resolv.conf
        line: "nameserver 127.0.0.1"
        insertbefore: BOF
      when: not systemd_resolved_check.stat.exists

    - name: Final base setup summary
      debug:
        msg: |
          ========================================
          Base Setup Complete for {{ inventory_hostname }}
          ========================================
          - Base packages installed
          - Timezone set to UTC
          - Sysctl settings configured
          - HashiCorp repository added
          - Consul/Nomad directories created
          - DNS configuration prepared for Consul

          Container is ready for service installation:
          - Run 02-install-consul.yml to install Consul
          - Run 03-install-nomad.yml to install Nomad
          - Run 05-install-postgres.yml for database nodes
          ========================================

    - name: Configure GPU support in containers
      when: inventory_hostname in gpu_passthrough_containers
      block:
        - name: Check NVIDIA device accessibility
          stat:
            path: "{{ item }}"
          loop:
            - /dev/nvidia0
            - /dev/nvidiactl
            - /dev/nvidia-uvm
          register: nvidia_devices

        - name: Display device status
          debug:
            msg: |
              NVIDIA Device Status:
              {% for device in nvidia_devices.results %}
              {{ device.item }}: {{ 'Found' if device.stat.exists else 'Missing' }}
              {% endfor %}

        - name: Download NVIDIA Container Toolkit GPG key
          get_url:
            url: "https://nvidia.github.io/libnvidia-container/gpgkey"
            dest: "/tmp/nvidia-container-toolkit-gpgkey"
            mode: '0644'

        - name: Add NVIDIA Container Toolkit GPG key
          shell: |
            cat /tmp/nvidia-container-toolkit-gpgkey | gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
          args:
            creates: /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

        - name: Add NVIDIA Container Toolkit repository
          shell: |
            curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
            tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
          args:
            creates: /etc/apt/sources.list.d/nvidia-container-toolkit.list

        - name: Update apt cache after adding NVIDIA repository
          apt:
            update_cache: yes

        - name: Install NVIDIA Container Toolkit
          apt:
            name:
              - nvidia-container-toolkit
              - nvidia-container-runtime
            state: present
            update_cache: yes

        - name: Get NVIDIA driver version from host
          command: nvidia-smi --query-gpu=driver_version --format=csv,noheader
          register: nvidia_driver_version
          delegate_to: "{{ proxmox_node }}"
          ignore_errors: true

        - name: Set default driver version if detection failed
          set_fact:
            nvidia_driver_version_clean: "{{ nvidia_driver_version.stdout | default('575.57.08') | trim }}"

        - name: Install NVIDIA drivers in container
          shell: |
            DRIVER_VERSION="{{ nvidia_driver_version_clean }}"
            echo "Installing NVIDIA driver version: ${DRIVER_VERSION}"
            
            # Download and install the driver with --no-kernel-modules flag
            cd /tmp
            wget -q "https://us.download.nvidia.com/tesla/${DRIVER_VERSION}/NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run" || \
            wget -q "https://us.download.nvidia.com/XFree86/Linux-x86_64/${DRIVER_VERSION}/NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run"
            
            chmod +x "NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run"
            ./NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run --no-kernel-modules --silent || true
            rm -f "NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run"
          args:
            creates: /usr/bin/nvidia-smi

        - name: Create NVIDIA configuration directory
          file:
            path: /etc/nvidia
            state: directory
            mode: '0755'

        - name: Create NVIDIA runtime configuration
          copy:
            content: |
              # NVIDIA runtime configuration for containers
              disable-require = false
              
              [nvidia-container-cli]
              environment = []
              debug = "/var/log/nvidia-container-toolkit.log"
              ldcache = "/etc/ld.so.cache"
              load-kmods = false
              no-cgroups = true
              user = "root:root"
              ldconfig = "@/sbin/ldconfig"
              
              [nvidia-container-runtime]
              debug = "/var/log/nvidia-container-runtime.log"
              log-level = "info"
              mode = "auto"
            dest: /etc/nvidia/nvidia-container-runtime.config
            mode: '0644'

        - name: Configure NVIDIA container toolkit for LXC
          shell: |
            # Configure for LXC usage
            nvidia-ctk config --set nvidia-container-cli.no-cgroups=true --in-place
            
            # Also update the config file directly to ensure no-cgroups is set
            if [ -f /etc/nvidia-container-runtime/config.toml ]; then
              sed -i 's/^#no-cgroups = false/no-cgroups = true/' /etc/nvidia-container-runtime/config.toml
              sed -i 's/^no-cgroups = false/no-cgroups = true/' /etc/nvidia-container-runtime/config.toml
            fi
            
            # Ensure runtime hook is configured
            nvidia-ctk runtime configure --runtime=docker
          changed_when: false
          ignore_errors: true

        - name: Gather package facts
          package_facts:
            manager: auto

        - name: Configure Docker for GPU support
          when: 
            - inventory_hostname in gpu_passthrough_containers
            - "'docker' in (ansible_facts.packages | default({}))"
          block:
            - name: Configure Docker daemon for NVIDIA runtime
              copy:
                content: |
                  {
                    "default-runtime": "nvidia",
                    "runtimes": {
                      "nvidia": {
                        "path": "nvidia-container-runtime",
                        "runtimeArgs": []
                      }
                    }
                  }
                dest: /etc/docker/daemon.json
                mode: '0644'
                backup: yes

            - name: Restart Docker to apply GPU configuration
              systemd:
                name: docker
                state: restarted
                daemon_reload: yes

        - name: Install GPU health check script
          template:
            src: ../../templates/gpu-health-check.sh.j2
            dest: /usr/local/bin/gpu-health-check.sh
            mode: '0755'

        - name: Install GPU health check systemd service
          template:
            src: ../../templates/gpu-health-check.service.j2
            dest: /etc/systemd/system/gpu-health-check.service
            mode: '0644'

        - name: Install GPU health check timer
          template:
            src: ../../templates/gpu-health-check.timer.j2
            dest: /etc/systemd/system/gpu-health-check.timer
            mode: '0644'

        - name: Enable GPU health check timer
          systemd:
            name: gpu-health-check.timer
            enabled: yes
            state: started
            daemon_reload: yes

# Verification checks at the end
- name: Verify Infrastructure Setup
  hosts: proxmox_nodes
  gather_facts: false
  tasks:
    - name: Run infrastructure verification checks
      block:
        - name: Check all containers are running
          shell: |
            failed=0
            for vmid in {% for container in hostvars[inventory_hostname]['my_containers'] %}{{ container.id }} {% endfor %}; do
              status=$(pct status $vmid 2>/dev/null | grep -oP 'status: \K\w+' || echo "not_found")
              if [ "$status" != "running" ]; then
                echo "Container $vmid is not running (status: $status)"
                failed=1
              fi
            done
            exit $failed
          register: container_check
          changed_when: false
          failed_when: container_check.rc != 0

        - name: Verify Tailscale connectivity
          shell: |
            failed=0
            {% for container in hostvars[inventory_hostname]['my_containers'] %}
            # Check if tailscale is running and get IP
            ip=$(pct exec {{ container.id }} -- bash -c "tailscale ip -4 2>/dev/null || echo ''" 2>/dev/null | tr -d '\n')
            if [ -z "$ip" ]; then
              echo "Container {{ container.id }} ({{ container.name }}) - No Tailscale IP assigned"
              failed=1
            else
              echo "Container {{ container.id }} ({{ container.name }}) - Tailscale IP: $ip"
            fi
            {% endfor %}
            exit $failed
          register: tailscale_check
          changed_when: false
          failed_when: tailscale_check.rc != 0
          retries: 3
          delay: 20
          until: tailscale_check.rc == 0

        - name: Verify SSH connectivity to containers
          shell: |
            failed=0
            {% for container in hostvars[inventory_hostname]['my_containers'] %}
            {% set container_name = container.name %}
            {% for host in groups['all'] %}
            {% if hostvars[host]['inventory_hostname'] == container_name %}
            if ! ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no {{ hostvars[host].tailscale_ip | default('') }} "echo 'SSH OK'" &>/dev/null; then
              echo "Cannot SSH to {{ container_name }} ({{ hostvars[host].tailscale_ip | default('no IP') }})"
              failed=1
            fi
            {% endif %}
            {% endfor %}
            {% endfor %}
            exit $failed
          register: ssh_check
          changed_when: false
          failed_when: false # Don't fail, just report

        - name: Display verification summary
          debug:
            msg: |
              ========================================
              Infrastructure Verification Summary
              ========================================
              Container Status: {{ 'PASS' if container_check.rc == 0 else 'FAIL' }}
              Tailscale Status: {{ 'PASS' if tailscale_check.rc == 0 else 'FAIL' }}
              SSH Connectivity: {{ 'PASS' if ssh_check.rc == 0 else 'WARNING' }}

              {% if container_check.stdout %}
              Container Issues:
              {{ container_check.stdout }}
              {% endif %}

              {% if tailscale_check.stdout %}
              Tailscale Info:
              {{ tailscale_check.stdout }}
              {% endif %}

              {% if ssh_check.stdout %}
              SSH Issues:
              {{ ssh_check.stdout }}
              {% endif %}
              
              {% if gpu_enabled_hosts[inventory_hostname] | default(false) %}
              GPU Configuration:
              - GPU Host: {{ inventory_hostname }}
              - GPU Containers: {{ gpu_passthrough_containers | join(', ') }}
              {% endif %}
              ========================================

  handlers:
    - name: restart systemd-resolved
      systemd:
        name: systemd-resolved
        state: restarted
